import chainlit as cl
import json
import networkx as nx
from networkx.readwrite import json_graph
from openai import OpenAI
import os
from typing import List, Dict, Tuple, Optional
import logging
from datetime import datetime
import asyncio
import re

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EnhancedKnowledgeGraphChatbot:
    """Enhanced Chainlit chatbot with advanced knowledge graph capabilities"""
    
    def __init__(self, kg_path: str = "knowledge_graph.json", model: str = "gpt-4o"):
        self.kg_path = kg_path
        self.model = model
        self.graph = None
        self.client = None
        self.use_legacy_api = False  # Flag for API compatibility
        self.entity_cache = {}
        self.frequent_queries = {
            "èª²ç¨‹è¦æ±‚": ["å­¸å£«å­¸ä½èª²ç¨‹", "ä¿®è®€å¹´æœŸåŠç•¢æ¥­å­¸åˆ†", "ç•¢æ¥­è³‡æ ¼"],
            "å­¸ç”Ÿæ”¿ç­–": ["å­¸ç”Ÿç´€å¾‹å®ˆå‰‡", "å­¸ç”Ÿ", "å¹³ç­‰æ©Ÿæœƒæ”¿ç­–"],
            "è€ƒè©¦è¦å®š": ["è€ƒè©¦", "è©•ä¼°æˆ–è€ƒæ ¸", "è£œè€ƒ"],
            "ç ”ç©¶å€«ç†": ["ç ”ç©¶é“å¾·æº–å‰‡", "ç ”ç©¶è€…", "ç ”ç©¶åƒèˆ‡è€…"],
            "AIå·¥å…·": ["ç”Ÿæˆå¼ AI å·¥å…·", "å­¸æ¥­ä¸èª å¯¦è¡Œç‚º"],
            "å¯¦ç¿’ç›¸é—œ": ["å¯¦ç¿’", "å¯¦ç¿’å–®ä½", "æœ‰é—œå­¸ç”Ÿå¯¦ç¿’æ”¯æ´"]
        }
        self.load_knowledge_graph()
        self.setup_openai()
    
    def setup_openai(self):
        """Initialize OpenAI client"""
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OpenAI API key not found. Set OPENAI_API_KEY environment variable.")
        
        try:
            # Initialize OpenAI client with minimal parameters
            self.client = OpenAI(api_key=api_key)
            logger.info(f"OpenAI client initialized with model: {self.model}")
        except Exception as e:
            logger.error(f"Failed to initialize OpenAI client: {e}")
            # Fallback: try with older initialization method
            try:
                import openai
                openai.api_key = api_key
                self.client = openai
                self.use_legacy_api = True
                logger.info("Using legacy OpenAI API")
            except Exception as e2:
                raise ValueError(f"Cannot initialize OpenAI client: {e}. Please update openai library: pip install openai>=1.0.0")
    
    def load_knowledge_graph(self):
        """Load knowledge graph from JSON file"""
        try:
            with open(self.kg_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.graph = json_graph.node_link_graph(data)
            logger.info(f"Knowledge graph loaded: {len(self.graph.nodes)} nodes, {len(self.graph.edges)} edges")
            
            # Store metadata
            self.metadata = data.get('metadata', {})
            
            # Build entity cache for faster searching
            self._build_entity_cache()
            
        except FileNotFoundError:
            logger.error(f"Knowledge graph file not found: {self.kg_path}")
            raise
        except Exception as e:
            logger.error(f"Error loading knowledge graph: {e}")
            raise
    
    def _build_entity_cache(self):
        """Build cache for faster entity searching"""
        self.entity_cache = {
            'by_keywords': {},
            'by_category': {},
            'entity_info': {}
        }
        
        for node in self.graph.nodes(data=True):
            entity_name = node[0]
            entity_data = node[1]
            
            # Store entity information
            self.entity_cache['entity_info'][entity_name] = {
                'name': entity_name,
                'type': entity_data.get('type', 'entity'),
                'size': entity_data.get('size', 5),
                'connections': len(list(self.graph.neighbors(entity_name)))
            }
            
            # Index by keywords
            keywords = self._extract_keywords(entity_name)
            for keyword in keywords:
                if keyword not in self.entity_cache['by_keywords']:
                    self.entity_cache['by_keywords'][keyword] = []
                self.entity_cache['by_keywords'][keyword].append(entity_name)
    
    def _extract_keywords(self, text: str) -> List[str]:
        """Extract keywords from entity name"""
        # Simple keyword extraction for Chinese and English
        keywords = []
        
        # Add full text
        keywords.append(text.lower())
        
        # Split by common separators
        parts = re.split(r'[ã€ï¼Œã€‚ï¼ï¼Ÿ\s\-_/]+', text)
        for part in parts:
            if len(part) > 1:
                keywords.append(part.lower())
        
        # Extract individual Chinese characters for fuzzy matching
        chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
        keywords.extend(chinese_chars)
        
        return list(set(keywords))
    
    def smart_search_entities(self, query: str, max_results: int = 10) -> List[Dict]:
        """Enhanced entity search with scoring"""
        query_lower = query.lower()
        matches = []
        
        # Exact matches
        for entity in self.graph.nodes():
            score = 0
            
            # Exact match
            if query_lower == entity.lower():
                score = 100
            # Contains query
            elif query_lower in entity.lower():
                score = 80
            # Character overlap for Chinese
            elif self._calculate_character_overlap(query, entity) > 0.5:
                score = 60
            # Keyword matches
            elif any(keyword in entity.lower() for keyword in query_lower.split()):
                score = 40
            
            if score > 0:
                matches.append({
                    'entity': entity,
                    'score': score,
                    'info': self.entity_cache['entity_info'].get(entity, {})
                })
        
        # Sort by score and return top results
        matches.sort(key=lambda x: x['score'], reverse=True)
        return matches[:max_results]
    
    def _calculate_character_overlap(self, query: str, entity: str) -> float:
        """Calculate character overlap ratio for Chinese text"""
        query_chars = set(query)
        entity_chars = set(entity)
        
        if not query_chars:
            return 0
        
        overlap = len(query_chars.intersection(entity_chars))
        return overlap / len(query_chars)
    
    def get_entity_context(self, entity: str, depth: int = 2) -> Dict:
        """Get comprehensive context for an entity"""
        if entity not in self.graph:
            return {}
        
        context = {
            'entity': entity,
            'direct_relationships': [],
            'related_policies': [],
            'relevant_procedures': [],
            'connected_services': []
        }
        
        # Get direct relationships
        for target in self.graph.successors(entity):
            edge_data = self.graph.get_edge_data(entity, target)
            for edge_attrs in edge_data.values():
                context['direct_relationships'].append({
                    'target': target,
                    'relation': edge_attrs.get('relation', 'related'),
                    'type': 'outgoing'
                })
        
        for source in self.graph.predecessors(entity):
            edge_data = self.graph.get_edge_data(source, entity)
            for edge_attrs in edge_data.values():
                context['direct_relationships'].append({
                    'source': source,
                    'relation': edge_attrs.get('relation', 'related'),
                    'type': 'incoming'
                })
        
        # Categorize relationships
        for rel in context['direct_relationships']:
            target_or_source = rel.get('target') or rel.get('source')
            if any(keyword in target_or_source for keyword in ['æ”¿ç­–', 'å®ˆå‰‡', 'è¦ç¯„']):
                context['related_policies'].append(target_or_source)
            elif any(keyword in target_or_source for keyword in ['ç”³è«‹', 'ç¨‹åº', 'æ‰‹çºŒ']):
                context['relevant_procedures'].append(target_or_source)
            elif any(keyword in target_or_source for keyword in ['éƒ¨', 'ä¸­å¿ƒ', 'æœå‹™']):
                context['connected_services'].append(target_or_source)
        
        return context
    
    def suggest_related_queries(self, current_query: str) -> List[str]:
        """Suggest related queries based on current query"""
        suggestions = []
        
        # Check frequent query categories
        for category, entities in self.frequent_queries.items():
            if any(keyword in current_query for keyword in entities):
                suggestions.append(f"æ›´å¤šé—œæ–¼{category}çš„ä¿¡æ¯")
        
        # Find related entities
        entities = self.smart_search_entities(current_query, 5)
        for entity_info in entities[:3]:
            entity_name = entity_info['entity']
            neighbors = list(self.graph.neighbors(entity_name))
            for neighbor in neighbors[:2]:
                suggestions.append(f"{entity_name}èˆ‡{neighbor}çš„é—œä¿‚")
        
        return list(set(suggestions))[:5]
    
    def generate_comprehensive_response(self, user_query: str) -> Dict:
        """Generate comprehensive response with multiple information sources"""
        
        # 1. Search for relevant entities
        relevant_entities = self.smart_search_entities(user_query, 8)
        
        # 2. Get context for top entities
        contexts = []
        for entity_info in relevant_entities[:5]:
            entity = entity_info['entity']
            context = self.get_entity_context(entity)
            if context:
                contexts.append(context)
        
        # 3. Prepare comprehensive knowledge base
        kg_context = self._format_comprehensive_context(contexts, relevant_entities)
        
        # 4. Generate suggestions
        suggestions = self.suggest_related_queries(user_query)
        
        # 5. Create GPT prompt
        system_prompt = """ä½ æ˜¯æ¾³é–€æ—…éŠå¤§å­¸çš„é«˜ç´šæ™ºèƒ½åŠ©æ‰‹ï¼Œå°ˆé–€æä¾›æº–ç¢ºã€å…¨é¢çš„å¤§å­¸ä¿¡æ¯è«®è©¢æœå‹™ã€‚

ä½ çš„è·è²¬ï¼š
1. åŸºæ–¼çŸ¥è­˜åœ–è­œæä¾›æº–ç¢ºçš„æ”¿ç­–è§£é‡‹
2. æŒ‡å°å­¸ç”Ÿäº†è§£ç¨‹åºå’Œè¦æ±‚
3. è§£é‡‹å¤§å­¸è¦å®šå’Œæ¨™æº–
4. æä¾›ç›¸é—œæœå‹™å’Œæ”¯æ´ä¿¡æ¯
5. ç¢ºä¿ä¿¡æ¯çš„æ™‚æ•ˆæ€§å’Œæº–ç¢ºæ€§

å›ç­”æŒ‡å—ï¼š
- ä½¿ç”¨ç¹é«”ä¸­æ–‡
- æä¾›çµæ§‹åŒ–å’Œè©³ç´°çš„å›ç­”
- å¼•ç”¨å…·é«”çš„æ”¿ç­–æˆ–è¦å®šåç¨±
- åŒ…å«å¯¦ç”¨çš„æ“ä½œå»ºè­°
- ç•¶ä¿¡æ¯ä¸å®Œæ•´æ™‚ï¼Œå»ºè­°è¯ç¹«ç›¸é—œéƒ¨é–€
- ä¿æŒå°ˆæ¥­å’Œå‹å¥½çš„èªèª¿"""

        user_prompt = f"""ç”¨æˆ¶æŸ¥è©¢: {user_query}

çŸ¥è­˜åœ–è­œç›¸é—œä¿¡æ¯:
{kg_context}

è«‹æä¾›å…¨é¢ã€æº–ç¢ºçš„å›ç­”ï¼ŒåŒ…æ‹¬ï¼š
1. ç›´æ¥å›ç­”ç”¨æˆ¶å•é¡Œ
2. ç›¸é—œæ”¿ç­–æˆ–è¦å®šçš„è§£é‡‹
3. å…·é«”çš„æ“ä½œæ­¥é©Ÿï¼ˆå¦‚é©ç”¨ï¼‰
4. ç›¸é—œéƒ¨é–€æˆ–æœå‹™çš„è¯ç¹«å»ºè­°
5. æ³¨æ„äº‹é …æˆ–é‡è¦æé†’

è«‹ç¢ºä¿å›ç­”çµæ§‹æ¸…æ™°ï¼Œæ˜“æ–¼ç†è§£ã€‚"""

        try:
            # Call GPT-4o with version compatibility
            if hasattr(self, 'use_legacy_api') and self.use_legacy_api:
                # Legacy API call
                response = self.client.ChatCompletion.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.2,
                    max_tokens=1500
                )
                answer = response.choices[0].message.content
            else:
                # Modern API call
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.2,
                    max_tokens=1500
                )
                answer = response.choices[0].message.content
            
            return {
                'answer': answer,
                'relevant_entities': [e['entity'] for e in relevant_entities[:5]],
                'suggestions': suggestions,
                'context_used': len(contexts) > 0
            }
            
        except Exception as e:
            logger.error(f"Error calling GPT-4o: {e}")
            return {
                'answer': "æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„å•é¡Œæ™‚å‡ºç¾éŒ¯èª¤ã€‚è«‹ç¨å¾Œå†è©¦ã€‚",
                'relevant_entities': [],
                'suggestions': [],
                'context_used': False
            }
    
    def _format_comprehensive_context(self, contexts: List[Dict], entities: List[Dict]) -> str:
        """Format comprehensive context for GPT"""
        context_parts = []
        
        # Add entity overview
        if entities:
            context_parts.append("ç›¸é—œå¯¦é«”æ¦‚è¦½:")
            for entity_info in entities[:5]:
                entity = entity_info['entity']
                score = entity_info['score']
                connections = entity_info['info'].get('connections', 0)
                context_parts.append(f"- {entity} (ç›¸é—œåº¦: {score}, é€£æ¥æ•¸: {connections})")
        
        # Add detailed contexts
        for context in contexts:
            entity = context['entity']
            context_parts.append(f"\nã€{entity}ã€‘è©³ç´°ä¿¡æ¯:")
            
            # Direct relationships
            if context['direct_relationships']:
                context_parts.append("é—œä¿‚:")
                for rel in context['direct_relationships'][:8]:
                    if rel['type'] == 'outgoing':
                        context_parts.append(f"  â€¢ {entity} {rel['relation']} {rel['target']}")
                    else:
                        context_parts.append(f"  â€¢ {rel['source']} {rel['relation']} {entity}")
            
            # Related policies
            if context['related_policies']:
                context_parts.append(f"ç›¸é—œæ”¿ç­–: {', '.join(context['related_policies'][:3])}")
            
            # Procedures
            if context['relevant_procedures']:
                context_parts.append(f"ç›¸é—œç¨‹åº: {', '.join(context['relevant_procedures'][:3])}")
            
            # Services
            if context['connected_services']:
                context_parts.append(f"ç›¸é—œæœå‹™: {', '.join(context['connected_services'][:3])}")
        
        return "\n".join(context_parts)

# Initialize the enhanced chatbot
enhanced_kg_chatbot = None

@cl.on_chat_start
async def start():
    """Initialize the enhanced chatbot when chat starts"""
    global enhanced_kg_chatbot
    
    try:
        # Show loading message
        loading_msg = cl.Message(content="ğŸ”„ æ­£åœ¨åˆå§‹åŒ–çŸ¥è­˜åœ–è­œç³»çµ±...")
        await loading_msg.send()
        
        # Initialize the knowledge graph chatbot
        enhanced_kg_chatbot = EnhancedKnowledgeGraphChatbot()
        
        # Update loading message
        await loading_msg.update(content="âœ… ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼")
        
        # Welcome message with quick actions
        welcome_msg = f"""# ğŸ“ æ¾³é–€æ—…éŠå¤§å­¸æ™ºèƒ½åŠ©æ‰‹ (å¢å¼·ç‰ˆ)

æ­¡è¿ä½¿ç”¨æ¾³é–€æ—…éŠå¤§å­¸æ™ºèƒ½çŸ¥è­˜åœ–è­œåŠ©æ‰‹ï¼æˆ‘å·²ç¶“æº–å‚™å¥½ç‚ºæ‚¨æä¾›å…¨é¢çš„æŸ¥è©¢æœå‹™ã€‚

## ğŸ“Š çŸ¥è­˜åº«çµ±è¨ˆ
- ğŸ§  **å¯¦é«”æ•¸é‡**: {len(enhanced_kg_chatbot.graph.nodes)} å€‹
- ğŸ”— **é—œä¿‚æ•¸é‡**: {len(enhanced_kg_chatbot.graph.edges)} å€‹  
- ğŸ“… **æœ€å¾Œæ›´æ–°**: {enhanced_kg_chatbot.metadata.get('created', 'N/A')}

## ğŸ” æˆ‘å¯ä»¥å¹«åŠ©æ‚¨æŸ¥è©¢

### ğŸ“š å­¸è¡“ç›¸é—œ
- èª²ç¨‹è¦æ±‚å’Œç•¢æ¥­æ¢ä»¶
- è©•ä¼°æ–¹æ³•å’Œè€ƒè©¦è¦å®š
- å­¸åˆ†è¨ˆç®—å’Œè½‰æ›

### ğŸ‘¨â€ğŸ“ å­¸ç”Ÿäº‹å‹™  
- å­¸ç”Ÿæ¬Šåˆ©å’Œè²¬ä»»
- ç´€å¾‹å®ˆå‰‡å’Œè™•åˆ†ç¨‹åº
- ç”³è«‹æµç¨‹å’Œæ‰‹çºŒ

### ğŸ”¬ ç ”ç©¶æ”¯æ´
- ç ”ç©¶é“å¾·æº–å‰‡
- å­¸è¡“èª ä¿¡æ”¿ç­–
- å¯¦ç¿’å®‰æ’å’Œæ”¯æ´

### ğŸ¤– AIå·¥å…·ä½¿ç”¨
- ç”Ÿæˆå¼AIå·¥å…·æ”¿ç­–
- å­¸è¡“èª å¯¦è¡Œç‚ºè¦ç¯„

## ğŸ’¡ ä½¿ç”¨æç¤º
è¼¸å…¥æ‚¨çš„å•é¡Œï¼Œæˆ‘æœƒï¼š
1. ğŸ” æœç´¢ç›¸é—œçš„çŸ¥è­˜å¯¦é«”
2. ğŸ“Š åˆ†æå¯¦é«”ä¹‹é–“çš„é—œä¿‚
3. ğŸ¤– ç”Ÿæˆæº–ç¢ºçš„å›ç­”
4. ğŸ’¡ æä¾›ç›¸é—œå»ºè­°

è«‹è¼¸å…¥æ‚¨çš„å•é¡Œé–‹å§‹æŸ¥è©¢ï¼"""

        await cl.Message(content=welcome_msg).send()
        
        # Add quick action buttons
        actions = [
            cl.Action(name="èª²ç¨‹è¦æ±‚", value="èª²ç¨‹è¦æ±‚", description="æŸ¥è©¢èª²ç¨‹å’Œç•¢æ¥­è¦æ±‚"),
            cl.Action(name="å­¸ç”Ÿæ”¿ç­–", value="å­¸ç”Ÿæ”¿ç­–", description="äº†è§£å­¸ç”Ÿç›¸é—œæ”¿ç­–"),
            cl.Action(name="è€ƒè©¦è¦å®š", value="è€ƒè©¦è¦å®š", description="æŸ¥çœ‹è€ƒè©¦å’Œè©•ä¼°è¦å®š"),
            cl.Action(name="ç ”ç©¶å€«ç†", value="ç ”ç©¶å€«ç†", description="ç ”ç©¶é“å¾·å’Œå­¸è¡“èª ä¿¡"),
            cl.Action(name="AIå·¥å…·", value="AIå·¥å…·", description="ç”Ÿæˆå¼AIå·¥å…·ä½¿ç”¨æŒ‡å¼•"),
        ]
        
        await cl.Message(
            content="ğŸš€ **å¿«é€ŸæŸ¥è©¢**: é»æ“Šä¸‹æ–¹æŒ‰éˆ•å¿«é€ŸæŸ¥è©¢å¸¸è¦‹å•é¡Œ",
            actions=actions
        ).send()
        
    except Exception as e:
        error_msg = f"""âŒ **åˆå§‹åŒ–éŒ¯èª¤**

éŒ¯èª¤ä¿¡æ¯: {str(e)}

è«‹æª¢æŸ¥ï¼š
1. `knowledge_graph.json` æ–‡ä»¶æ˜¯å¦å­˜åœ¨
2. OpenAI API å¯†é‘°æ˜¯å¦æ­£ç¢ºè¨­å®š
3. ç¶²çµ¡é€£æ¥æ˜¯å¦æ­£å¸¸

æ‚¨å¯ä»¥å˜—è©¦é‡æ–°é–‹å§‹å°è©±ã€‚"""
        await cl.Message(content=error_msg).send()

@cl.action_callback("èª²ç¨‹è¦æ±‚")
async def query_course_requirements(action):
    """Handle course requirements query"""
    await handle_predefined_query("è«‹å‘Šè¨´æˆ‘é—œæ–¼å­¸å£«å­¸ä½èª²ç¨‹çš„è¦æ±‚å’Œç•¢æ¥­æ¢ä»¶")

@cl.action_callback("å­¸ç”Ÿæ”¿ç­–")
async def query_student_policies(action):
    """Handle student policies query"""
    await handle_predefined_query("å­¸ç”Ÿç´€å¾‹å®ˆå‰‡å’Œç›¸é—œæ”¿ç­–æœ‰å“ªäº›ï¼Ÿ")

@cl.action_callback("è€ƒè©¦è¦å®š")
async def query_exam_regulations(action):
    """Handle exam regulations query"""
    await handle_predefined_query("è€ƒè©¦å’Œè©•ä¼°çš„ç›¸é—œè¦å®šæ˜¯ä»€éº¼ï¼Ÿ")

@cl.action_callback("ç ”ç©¶å€«ç†")
async def query_research_ethics(action):
    """Handle research ethics query"""
    await handle_predefined_query("ç ”ç©¶é“å¾·æº–å‰‡å’Œå­¸è¡“èª ä¿¡æ”¿ç­–")

@cl.action_callback("AIå·¥å…·")
async def query_ai_tools(action):
    """Handle AI tools query"""
    await handle_predefined_query("ç”Ÿæˆå¼AIå·¥å…·çš„ä½¿ç”¨æ”¿ç­–å’ŒæŒ‡å¼•")

async def handle_predefined_query(query: str):
    """Handle predefined queries"""
    global enhanced_kg_chatbot
    
    if not enhanced_kg_chatbot:
        await cl.Message(content="âŒ ç³»çµ±æœªåˆå§‹åŒ–ï¼Œè«‹é‡æ–°é–‹å§‹å°è©±ã€‚").send()
        return
    
    # Process the query
    await process_query(query)

@cl.on_message
async def main(message: cl.Message):
    """Handle user messages"""
    await process_query(message.content)

async def process_query(user_query: str):
    """Process user query with enhanced features"""
    global enhanced_kg_chatbot
    
    if not enhanced_kg_chatbot:
        await cl.Message(content="âŒ ç³»çµ±æœªåˆå§‹åŒ–ï¼Œè«‹é‡æ–°é–‹å§‹å°è©±ã€‚").send()
        return
    
    # Show detailed processing steps
    async with cl.Step(name="ğŸ” æ™ºèƒ½æœç´¢", type="tool") as search_step:
        search_step.output = "æ­£åœ¨æœç´¢çŸ¥è­˜åœ–è­œä¸­çš„ç›¸é—œå¯¦é«”..."
        
        # Search for relevant entities
        entities = enhanced_kg_chatbot.smart_search_entities(user_query, 8)
        
        if entities:
            entity_list = [f"{e['entity']} (ç›¸é—œåº¦: {e['score']})" for e in entities[:5]]
            search_step.output = f"âœ… æ‰¾åˆ° {len(entities)} å€‹ç›¸é—œå¯¦é«”:\n" + "\n".join([f"â€¢ {e}" for e in entity_list])
        else:
            search_step.output = "âš ï¸ æœªæ‰¾åˆ°ç›´æ¥åŒ¹é…çš„å¯¦é«”ï¼Œå°‡é€²è¡Œæ™ºèƒ½åˆ†æ..."
    
    async with cl.Step(name="ğŸ“Š é—œä¿‚åˆ†æ", type="tool") as analysis_step:
        analysis_step.output = "æ­£åœ¨åˆ†æå¯¦é«”é—œä¿‚å’Œç²å–ä¸Šä¸‹æ–‡ä¿¡æ¯..."
        
        # Get contexts
        contexts = []
        for entity_info in entities[:3]:
            context = enhanced_kg_chatbot.get_entity_context(entity_info['entity'])
            if context:
                contexts.append(context)
        
        if contexts:
            analysis_step.output = f"âœ… åˆ†æäº† {len(contexts)} å€‹æ ¸å¿ƒå¯¦é«”çš„é—œä¿‚ç¶²çµ¡\n"
            for i, ctx in enumerate(contexts[:3], 1):
                rel_count = len(ctx.get('direct_relationships', []))
                analysis_step.output += f"â€¢ {ctx['entity']}: {rel_count} å€‹ç›´æ¥é—œä¿‚\n"
        else:
            analysis_step.output = "âš ï¸ æœªæ‰¾åˆ°å…·é«”çš„é—œä¿‚ä¿¡æ¯ï¼Œå°‡åŸºæ–¼ä¸€èˆ¬çŸ¥è­˜å›ç­”"
    
    async with cl.Step(name="ğŸ¤– ç”Ÿæˆå›ç­”", type="llm") as response_step:
        response_step.output = "æ­£åœ¨ä½¿ç”¨ GPT-4o ç”Ÿæˆæ™ºèƒ½å›ç­”..."
        
        # Generate comprehensive response
        result = enhanced_kg_chatbot.generate_comprehensive_response(user_query)
        
        response_step.output = "âœ… å›ç­”å·²ç”Ÿæˆï¼ŒåŒ…å«ç›¸é—œå¯¦é«”å’Œå»ºè­°"
    
    # Main response
    response_content = result['answer']
    
    # Add entity information if available
    if result['relevant_entities']:
        response_content += f"\n\n## ğŸ“‹ ç›¸é—œå¯¦é«”\n"
        for entity in result['relevant_entities']:
            response_content += f"â€¢ {entity}\n"
    
    await cl.Message(content=response_content).send()
    
    # Add suggestions if available
    if result['suggestions']:
        suggestions_actions = []
        for i, suggestion in enumerate(result['suggestions'][:3]):
            suggestions_actions.append(
                cl.Action(
                    name=f"suggestion_{i}",
                    value=suggestion,
                    description=f"æŸ¥è©¢: {suggestion}"
                )
            )
        
        await cl.Message(
            content="ğŸ’¡ **ç›¸é—œå»ºè­°**: æ‚¨å¯èƒ½é‚„æƒ³äº†è§£",
            actions=suggestions_actions
        ).send()

@cl.action_callback("suggestion_0")
async def handle_suggestion_0(action):
    await handle_predefined_query(action.value)

@cl.action_callback("suggestion_1") 
async def handle_suggestion_1(action):
    await handle_predefined_query(action.value)

@cl.action_callback("suggestion_2")
async def handle_suggestion_2(action):
    await handle_predefined_query(action.value)

@cl.on_stop
async def stop():
    """Clean up when chat stops"""
    goodbye_msg = """ğŸ‘‹ **æ„Ÿè¬ä½¿ç”¨æ¾³é–€æ—…éŠå¤§å­¸æ™ºèƒ½åŠ©æ‰‹ï¼**

å¸Œæœ›æˆ‘çš„å›ç­”å°æ‚¨æœ‰æ‰€å¹«åŠ©ã€‚å¦‚éœ€æ›´å¤šä¿¡æ¯ï¼Œè«‹ï¼š

ğŸ“ **è¯ç¹«æ•™å‹™éƒ¨**: æŸ¥è©¢å­¸è¡“ç›¸é—œå•é¡Œ
ğŸ« **è¨ªå•å®˜æ–¹ç¶²ç«™**: ç²å–æœ€æ–°æ”¿ç­–æ›´æ–°  
ğŸ“§ **ç™¼é€éƒµä»¶**: ç²å–å…·é«”æ¡ˆä¾‹å”åŠ©

ç¥æ‚¨å­¸ç¿’é †åˆ©ï¼ğŸ“"""
    
    await cl.Message(content=goodbye_msg).send()

if __name__ == "__main__":
    print("ğŸš€ Starting Enhanced Chainlit Knowledge Graph Chatbot...")
    print("ğŸ“‹ Features:")
    print("   â€¢ Smart entity search with scoring")
    print("   â€¢ Comprehensive relationship analysis") 
    print("   â€¢ Query suggestions")
    print("   â€¢ Quick action buttons")
    print("   â€¢ Enhanced user interface")
    print("\nğŸ’¡ Run with: chainlit run enhanced_chainlit_chatbot.py -w")
    print("ğŸŒ Then open: http://localhost:8000")